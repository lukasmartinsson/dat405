{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Assignment_7_NN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 7: Neural Networks using Keras and Tensorflow \r\n",
        "Please see the associated document for questions. If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs."
      ],
      "metadata": {
        "id": "rHoSDyYpdh-s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# imports\r\n",
        "from __future__ import print_function\r\n",
        "import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras import backend as K\r\n",
        "import tensorflow as tf\r\n",
        "from matplotlib import pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "02ZYZ-WmdhwH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Hyper-parameters data-loading and formatting\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_classes = 10\r\n",
        "epochs = 10\r\n",
        "\r\n",
        "img_rows, img_cols = 28, 28\r\n",
        "\r\n",
        "(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n",
        "    input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n",
        "    input_shape = (img_rows, img_cols, 1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "metadata": {
        "id": "BJRCoRmew8Zd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a74f963-06c8-4ba7-fb03-889e43dfa15e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "-I3g1RrZ0wpI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = keras.utils.to_categorical(lbl_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(lbl_test, num_classes)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "UswCCQLS0s1I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "## Define model ##\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "               optimizer=keras.optimizers.SGD(lr = 0.1),\n",
        "        metrics=['accuracy'],)\n",
        "\n",
        "fit_info = model.fit(x_train, y_train,\n",
        "           batch_size=batch_size,\n",
        "           epochs=epochs,\n",
        "           verbose=1,\n",
        "           validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss: {}, Test accuracy {}'.format(score[0], score[1]))"
      ],
      "outputs": [],
      "metadata": {
        "id": "N7Aer42gk1W9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 4) Auto-Encoder for denoising\n"
      ],
      "metadata": {
        "id": "0I2Bkk_rhUnH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\n",
        "def salt_and_pepper(input, noise_level=0.5):\n",
        "    \"\"\"\n",
        "    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n",
        "    Parameters\n",
        "    ----------\n",
        "    input : tensor\n",
        "        The tensor to apply salt and pepper noise to.\n",
        "    noise_level : float\n",
        "        The amount of salt and pepper noise to add.\n",
        "    Returns\n",
        "    -------\n",
        "    tensor\n",
        "        Tensor with salt and pepper noise applied.\n",
        "    \"\"\"\n",
        "    # salt and pepper noise\n",
        "    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n",
        "    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n",
        "    c = (a==0) * b\n",
        "    return input * a + c\n",
        "\n",
        "\n",
        "#data preparation\n",
        "flattened_x_train = x_train.reshape(-1,784)\n",
        "flattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n",
        "\n",
        "flattened_x_test = x_test.reshape(-1,784)\n",
        "flattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "yO0HxKeJ7WFw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "latent_dim = 96  \n",
        "\n",
        "input_image = keras.Input(shape=(784,))\n",
        "encoded = Dense(128, activation='relu')(input_image)\n",
        "encoded = Dense(latent_dim, activation='relu')(encoded)\n",
        "decoded = Dense(128, activation='relu')(encoded)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded)\n",
        "\n",
        "autoencoder = keras.Model(input_image, decoded)\n",
        "encoder_only = keras.Model(input_image, encoded)\n",
        "\n",
        "encoded_input = keras.Input(shape=(latent_dim,))\n",
        "decoder_layer = Sequential(autoencoder.layers[-2:])\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "outputs": [],
      "metadata": {
        "id": "0GZtZH4ScQeN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "fit_info_AE = autoencoder.fit(flattened_x_train_seasoned, flattened_x_train,\n",
        "                epochs=32,\n",
        "                batch_size=64,\n",
        "                shuffle=True,\n",
        "                validation_data=(flattened_x_test_seasoneed, flattened_x_test))\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "56iJOKNIKfuB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "0Mr8NGwJ95Sf"
      }
    }
  ]
}