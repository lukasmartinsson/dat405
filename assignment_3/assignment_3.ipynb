{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Assignment 3:** Clustering\n",
    "\n",
    "### **Worked hours:** ...\n",
    "### **Authors:** Sidner Magnéli, Lukas Martinsson \n",
    "\n",
    "___"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# global imports and configuration\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set plot style\n",
    "sns.set_style(\"darkgrid\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Part 1:** Show the distribution of phi and psi combinations using:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **1.a)** A scatter plot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "discussion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As one can see, three outliers were filtered out, and the regression line adjusted appropriately."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **1.b)** What are the values of the slope and intercept of the regression line?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Slope of the line:\n",
    "print('Slope of the line is:', model2.coef_)\n",
    "\n",
    "# Intercept of the line:\n",
    "print('Intercept at:',  model2.intercept_)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **1.c)** Use this model to predict the selling prices of houses which have living area 100 m2, 150 m2 and 200 m2. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an array with the specified living areas\n",
    "values = np.asarray([100,150,200])\n",
    "\n",
    "# Let the model predict the selling prices for those input values \n",
    "value = model.predict(values[:,np.newaxis])\n",
    "\n",
    "print('Selling price at 100 m^2:', int(value[0]) )\n",
    "print('Selling price at 159 m^2:', int(value[1]) )\n",
    "print('Selling price at 200 m^2:', int(value[2]) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **1.d)** Draw a residual plot."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Using seaborn a residual plot was created\n",
    "ax = sns.residplot(x=x_area,y=y_selling, lowess=True, color=\"g\")\n",
    "ax.set_title('Residual plot');"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **1.e)** Discuss the results, and how the model could be improved."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.scatter(x_area,y_selling, color='blue', label = 'Nonoutliers')\n",
    "plt.scatter(x_area_outlier,y_selling_outlier, color='red', label = 'Outliers')\n",
    "plt.plot(xfit,yfit,color='green', label = 'Regression model (mod)')\n",
    "plt.plot(x_fit,y_fit,color='orange', label = 'Regression model')\n",
    "\n",
    "plt.xlabel(\"Selling price\")\n",
    "plt.ylabel(\"Living area\")\n",
    "\n",
    "#Slope of the lines:\n",
    "print('Slope of the line is (original):', model.coef_)\n",
    "print('Slope of the line is (modified):', model2.coef_)\n",
    "\n",
    "#Intercept of the lines:\n",
    "print('Intercept at (original):',  model.intercept_)\n",
    "print('Intercept at (modified):',  model2.intercept_)\n",
    "plt.title('Comparison of regression models')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "By removing outliers, we can see that the regression lines slope shifts and intercepts at different point. Depending on the selling price/living area one wants to predict, these two different lines can give different predictions. It is hard to show which one is better than the other without using test data but it illustrates how difficult it is to choose which points are outliers and which are not. As mentioned above in **1.a)**, using a more robust model, such as **Huber regression** might also yield better results.\r\n",
    "\r\n",
    "Furthermore, as has been touched on above, adding additional features that one would expect to have an effect on the selling prices may also improve the performance of the model. For example by combining the biarea with the living area.\r\n",
    "\r\n",
    "Also plotting the average residual line (setting lowess) gives an indication if the data conforms to random erros or not, which could be cruicial in determining whether the model is valid"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Create an array with the values chosen\n",
    "values2 = np.asarray([75, 100, 150, 200])\n",
    "\n",
    "# Let the model predict the selling prices at those points\n",
    "value1 = model.predict(values2[:,np.newaxis])\n",
    "value2 = model2.predict(values2[:,np.newaxis])\n",
    "model_type = ['model', 'model2']\n",
    "\n",
    "print('Selling price at 75 m^2:', ('Original:'), int(value1[0]), ('Modified:'), int(value2[0]) )\n",
    "print('Selling price at 100 m^2:', ('Original:'), int(value1[1]), ('Modified:'), int(value2[1]) )\n",
    "print('Selling price at 150 m^2:', ('Original:'), int(value1[2]), ('Modified:'), int(value2[2]) )\n",
    "print('Selling price at 200 m^2:', ('Original:'), int(value1[3]), ('Modified:'), int(value2[3]) )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As a final note: As the code above illustrates the predictions can be extremely close or far apart depending on the selling price chosen. This goes to show that discarding outliers can have a large effect on the final model and it's prediction, and should be done with care."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "___\n",
    "## **Part 2**: Iris dataset \n",
    "\n",
    "In this question, you will use the Iris data set (“from sklearn.datasets import load_iris”)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **2.a)** Use a confusion matrix to evaluate the use of logistic regression to classify the iris data set."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create the df from load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# splits it into test and traing with a test of 25% of the total\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size=0.25)\n",
    "\n",
    "# generate a logisitc regression multiclass model\n",
    "# setting  multi_class='ovr' uses the One vs Rest schema, for which a separate model is trained for each class \n",
    "# predicting whether an observation is that class or not (thus making it a binary classification problem).\n",
    "model = LogisticRegression(solver='liblinear', multi_class='ovr').fit(X_train,y_train)\n",
    "\n",
    "# make classification\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# calculate model score (accuracy)\n",
    "score = model.score(X_test, y_test)\n",
    "\n",
    "# reate a confusion matrix and plots it\n",
    "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
    "\n",
    "# plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(9,9))\n",
    "sns.heatmap(cm, annot = True, fmt=\".3f\", linewidths=5, square=True, cmap='RdPu' )\n",
    "ax.set_xticklabels(iris.target_names)\n",
    "ax.set_yticklabels(iris.target_names)\n",
    "all_sample_title = 'Confusion matrix \\n\\nAccuracy Score: {0}'.format(score)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('predicted label')\n",
    "plt.title(all_sample_title, size = 15)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the confusion matrix shows the accuracy is 87%. Both **setosa** and **virginica** can be predicted with 100% accuracy, however **versicolor** is not as accurate, only at 69%, misinterpreted as **virginica** 31% of the times. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **2.b)** Use k-nearest neighbours to classify the iris data set with some different values for k, and with uniform and distance-based weights. What will happen when k grows larger for the different cases? Why?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "# Creating a for loop that create a plot with different weight and k to illustrate what happens when k grows larger \n",
    "# and how it differes between 'distance' and 'uniform'\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('Number of k')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Accuracy for different numbers of k', size = 15)\n",
    "\n",
    "l = list(range(1, 113))\n",
    "for weight in ['distance','uniform']:\n",
    "    accuracy_score = [] \n",
    "    for i in l:\n",
    "        # Create KNN Classifier\n",
    "        knn = KNeighborsClassifier(n_neighbors=i,weights=weight ) \n",
    "\n",
    "        #Train the model using the training sets\n",
    "        knn.fit(X_train, y_train)\n",
    "\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        # Model Accuracy, how often is the classifier correct?\n",
    "        accuracy_score.append(metrics.accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    if weight == 'uniform':\n",
    "        plt.plot(l,accuracy_score, label = 'Uniform weight', color = 'red')\n",
    "    else:\n",
    "        plt.plot(l,accuracy_score, label = 'Distance weight', color = 'blue')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the plot illustrates the distance based weight gives a linear and high accuracy for every k. Uniform based however differs greatly depending on k. Distance based is probably better through and through since it makes more sense to give a closer k a higher weight then a k far away. this is especially true when the k is high. This is because a high k probably results in a k really far away making as much a contribution to the prediction as a close k. Therefore, the unform weight loses accuracy the higher k becomes."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **2.c)** Compare the classification models for the iris data set that are generated by k-nearest neighbours (for the different settings from question 2b) and by logistic regression. Calculate confusion matrices for these models and discuss the performance of the various models."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we chose to create 4 different models by k-nearest neighbors. 2 uniform weight based and 2 distance weight based with the k value set to 35 and 75 respectively"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create KNN Classifier\n",
    "uniform35 = KNeighborsClassifier(n_neighbors=35,weights='uniform')\n",
    "uniform75 = KNeighborsClassifier(n_neighbors=75,weights='uniform')\n",
    "distance35 = KNeighborsClassifier(n_neighbors=35,weights='distance')\n",
    "distance75 = KNeighborsClassifier(n_neighbors=75,weights='distance')\n",
    "\n",
    "#Train the models using the training sets\n",
    "for classifier in [uniform35, uniform75, distance35, distance75]:\n",
    "  classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict the response for test datasets\n",
    "uniform35_predict = uniform35.predict(X_test)\n",
    "uniform75_predict = uniform75.predict(X_test)\n",
    "distance35_predict = distance35.predict(X_test)\n",
    "distance75_predict = distance75.predict(X_test)\n",
    "\n",
    "# model accuracy, how often is the classifier correct?\n",
    "uniform35_score = uniform35.score(X_test,y_test)\n",
    "uniform75_score = uniform75.score(X_test,y_test)\n",
    "distance35_score = distance35.score(X_test,y_test)\n",
    "distance75_score = distance75.score(X_test,y_test)\n",
    "\n",
    "# create confusion matrixes\n",
    "uniform35_cm = confusion_matrix(y_test, uniform35_predict, normalize = 'true')\n",
    "uniform75_cm = confusion_matrix(y_test, uniform75_predict, normalize = 'true')\n",
    "distance35_cm = confusion_matrix(y_test, distance35_predict, normalize = 'true')\n",
    "distance75_cm = confusion_matrix(y_test, distance75_predict, normalize = 'true')\n",
    "\n",
    "# plot confusion matrixes\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2, figsize=(10,10))\n",
    "sns.heatmap(uniform35_cm, ax = ax1, annot = True, fmt=\".3f\", linewidths=.5, square=True, cmap='RdPu' )\n",
    "sns.heatmap(uniform75_cm, ax = ax2, annot = True, fmt=\".3f\", linewidths=.5, square=True, cmap='RdPu' )\n",
    "sns.heatmap(distance35_cm, ax = ax3, annot = True, fmt=\".3f\", linewidths=.5, square=True, cmap='RdPu' )\n",
    "sns.heatmap(distance75_cm, ax = ax4, annot = True, fmt=\".3f\", linewidths=.5, square=True, cmap='RdPu' )\n",
    "\n",
    "# set labels\n",
    "ax1.set_xlabel('Predicted label')\n",
    "ax1.set_ylabel('Actual label')\n",
    "ax1.set_title('Uniform weight (k=35) \\n Accuracy Score: {0}'.format(uniform35_score), size=10)\n",
    "ax1.set_xticklabels(iris.target_names)\n",
    "ax1.set_yticklabels(iris.target_names)\n",
    "ax2.set_xlabel('Predicted label')\n",
    "ax2.set_ylabel('Actual label')\n",
    "ax2.set_title('Uniform weight (k=75) \\n Accuracy Score: {0}'.format(uniform75_score), size=10)\n",
    "ax2.set_xticklabels(iris.target_names)\n",
    "ax2.set_yticklabels(iris.target_names)\n",
    "ax3.set_xlabel('Predicted label')\n",
    "ax3.set_ylabel('Actual label')\n",
    "ax3.set_title('Distance weight (k=35) \\n Accuracy Score: {0}'.format(distance35_score), size=10)\n",
    "ax3.set_xticklabels(iris.target_names)\n",
    "ax3.set_yticklabels(iris.target_names)\n",
    "ax4.set_xlabel('Predicted label')\n",
    "ax4.set_ylabel('Actual label')\n",
    "ax4.set_title('Distance weight (k=75) \\n Accuracy Score: {0}'.format(distance75_score), size=10)\n",
    "ax4.set_xticklabels(iris.target_names)\n",
    "ax4.set_yticklabels(iris.target_names)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As one can see, the confusion matrix for the distance-based weight is the same while the uniform based differs. This more or less illustrates the same thing as the plot above however this shows 4 concert examples of this. Furthermore, this demonstrates that only versicolor is the one to get predicted wrongly, indicating that its points are probably less cluttered together then the other 2. One could argue that since it usually gets wrong assumed to be virginica it has to the same must be true for virginica, but since the accuracy is 100% across every confusion matrix the only conclusion is that virginica points are close together and versicolor is not, however the versicolor points are probably closer to virginica than setosa.\n",
    "\n",
    "Lastly when comparing knn to logistic regression (2a) one could see that knn has a higher accuracy 97% (at least if we use distances weights which vastly outperforms uniform on higher k values) compared to logistic regression which only had a accuracy of 87%"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Part 3**: Explain why it is important to use a separate test (and sometimes validation) set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Since when training a model, one usually tweaks it and for example removes outliers to improve accuracy. And let’s say that one was not to use a test set then the model after tweaking could theoretically achieve 100% accuracy on the set used. However, if one were to use it as a prediction model for another set the accuracy could be extremely low. Instead by using a test set one could tweak the model on the training set and then test it on test set. Then go back to the training set and tweak it further (which is basically a validation set, it seems that test and validation set are used somewhat lose). After a few iterations the model would then be able to more accurately predict data on both the test set and thus also new data.\r\n",
    "\r\n",
    "Furthermore, when designing, let's say a classification system, data scientists usually evaluate the performance of several different models with the validation dataset before selecting the best candidate. However, if they were to also evaluate the real-world performance of the system using that same dataset, the system would score much higher than if it were to be presented with new data as the model was selected because it performed well on that specific dataset.\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "dbeb9a3f8d3550cd62187319f560f680c2be241a530bbcc0135e6d432ea62fbc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}