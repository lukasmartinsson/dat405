{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Assignment&nbsp;7:&nbsp;Neural&nbsp;Networks&nbsp;using&nbsp;Keras&nbsp;and&nbsp;Tensorflow&nbsp;",
   "metadata": {
    "tags": [],
    "is_collapsed": false,
    "cell_id": "00000-45dced71-7681-4475-971e-649463295426",
    "deepnote_cell_type": "text-cell-h1"
   }
  },
  {
   "cell_type": "markdown",
   "source": "\nPlease see the associated document for questions. If you have problems with Keras and Tensorflow on your local installation please make sure they are updated. On Google Colab this notebook runs.",
   "metadata": {
    "id": "rHoSDyYpdh-s",
    "cell_id": "00000-1933ed77-1127-4395-99ec-46b392d40a67",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "02ZYZ-WmdhwH",
    "cell_id": "00001-5064d858-6f43-4902-b581-b2b7f141480e",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "cf068e77",
    "execution_start": 1634205441874,
    "execution_millis": 9480,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "# imports\nfrom __future__ import print_function\nfrom tensorflow import keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "BJRCoRmew8Zd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8a74f963-06c8-4ba7-fb03-889e43dfa15e",
    "cell_id": "00002-bb4f08e7-9e70-4e9e-96f6-e83a1d42e688",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "7f04d42d",
    "execution_start": 1634205451373,
    "execution_millis": 637,
    "deepnote_cell_type": "code"
   },
   "source": "# Hyper-parameters data-loading and formatting\n\nbatch_size = 128\nnum_classes = 10\nepochs = 10\n\nimg_rows, img_cols = 28, 28\n\n(x_train, lbl_train), (x_test, lbl_test) = mnist.load_data()\n\nif K.image_data_format() == \"channels_first\":\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n11493376/11490434 [==============================] - 0s 0us/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "metadata": {
    "id": "-I3g1RrZ0wpI",
    "cell_id": "00003-29f6f65b-15b6-4b03-86db-d3b3660d7f37",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "markdown",
   "source": "In order to simplify vector operations we normalize the pixels by scaling them from the range [0,255] down to [0,1], dividing each pixel by its max value 255. However, we first need to cast the elements of the tensors to `float` as python's division assignment operator `/=`, doesn't work with `integers` when the ouput is `float`",
   "metadata": {
    "tags": [],
    "cell_id": "00005-a1773d6e-474d-4d98-9f28-6c2c7cee9c20",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UswCCQLS0s1I",
    "cell_id": "00004-acb3cf64-92c2-4ffd-893d-99402c9fb423",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "fbcaacd3",
    "execution_start": 1634205452012,
    "execution_millis": 130,
    "deepnote_cell_type": "code"
   },
   "source": "x_train = x_train.astype(\"float32\")\nx_test = x_test.astype(\"float32\")\n\nx_train /= 255\nx_test /= 255\n\nprint(\"x_train shape:\", x_train.shape)\nprint(\"x_test shape:\", x_test.shape)\n",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "x_train shape: (60000, 28, 28, 1)\nx_test shape: (10000, 28, 28, 1)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "Next, we create a one-hot encoding of the digits 0-9, as classification models generally output a one-hot encoded vector with the same number of dimension as classes (10) in the dataset.",
   "metadata": {
    "tags": [],
    "cell_id": "00007-ff8485a7-3011-4a12-9dcd-f91be96fac50",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00007-cadeaa42-ca92-4496-8209-34475c81cf55",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3652dd02",
    "execution_start": 1634205452133,
    "execution_millis": 32,
    "deepnote_cell_type": "code"
   },
   "source": "y_train = keras.utils.to_categorical(lbl_train, num_classes)\ny_test = keras.utils.to_categorical(lbl_test, num_classes)\n\nprint('y_train shape, one-hot encoded:', y_train.shape)\nprint('y_test shape, one-hot encoded:', y_test.shape)  ",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "y_train shape, one-hot encoded: (60000, 10)\ny_test shape, one-hot encoded: (10000, 10)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Generating and training a model\nAt this point, the dataset has been prepared and it's time to generate, tweak and fit a model for prediction. Here, a sequential model is used, appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor..",
   "metadata": {
    "tags": [],
    "cell_id": "00010-8b87579e-6cd0-445e-8a59-cd067db5616f",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00010-89e20e24-2d5f-461e-bb1a-c5cbc62ea333",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "49e13650",
    "execution_start": 1634205452146,
    "execution_millis": 99,
    "deepnote_cell_type": "code"
   },
   "source": "## Define model ##\nmodel = Sequential()",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Layers used in the model\nThe first layer is added to flatten the input such that the number of dimensions correspond to the number of elements in the input tensor, since the next layer expects a vector as input. More specifically, each image is converted from a 28 x 28 matrix to a vector with 784 elements, \nAnother reason for this is to couple information that exists vertically as well as horizontally. There is no way to *couple* the information *across rows* in the pixel arrays representing the images, without either flatting or using a 2-dimensional kernel like a convolution (or maybe some other operation we haven’t considered yet). Without doing this, you can infer information on a row-by-row basis (“horizontally”), but there’s no way to combine information that exists across rows -- it’s like you have a set of disconnected horizontal slices of an image, but no way to “see” the vertical structures, until you either flatten or switch to 2d convolution. ",
   "metadata": {
    "tags": [],
    "cell_id": "00012-5a5911e5-aec8-42ed-908d-1717cb8d546b",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00011-80ced561-b58c-429c-bc91-3bb418ef2d40",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "6943cab8",
    "execution_start": 1634205452249,
    "execution_millis": 16,
    "deepnote_cell_type": "code"
   },
   "source": "model.add(Flatten())",
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The next two fully connected layers are what gives the network the complexity to, when correctly fitted, recognize the handwritten digits. These layers specify two arguments, the first one being the output format or the number neurons and the second one specfiying the **Rectified Linear Unit** as the activation function for the layers neurons. This activation function is what allows the layer to model nonlinear functions.",
   "metadata": {
    "tags": [],
    "cell_id": "00014-7bbe59f6-9f8b-4cec-8969-53670286c004",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00012-2f5f7ad7-454d-4803-b7f1-918a54e7a9f0",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "41b0b2ff",
    "execution_start": 1634205452273,
    "execution_millis": 12,
    "deepnote_cell_type": "code"
   },
   "source": "model.add(Dense(64, activation = 'relu'))\nmodel.add(Dense(64, activation = 'relu'))",
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "The final, so called, output layer should have it's output shape set to the expected output of the model. For the handwritten digit scenario, this might be to use one neuron per digit, in other words, a vector of 10 nodes. \nthis layer specify a different activation function,  Softmax, which outputs a vector that represents the probability distributions of a list of potential outcomes (digits 0-9) allowing the neural network to output the digit with highest probability value.",
   "metadata": {
    "tags": [],
    "cell_id": "00016-866fd96e-1996-4e75-939e-82d4a7e06296",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00013-7eddd7b1-2c23-4486-8b1f-7236a4c5f65c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "b8f566b4",
    "execution_start": 1634205452288,
    "execution_millis": 12,
    "deepnote_cell_type": "code"
   },
   "source": "model.add(Dense(num_classes, activation='softmax'))",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "#### Model configuration\nBelow, the model is configured to use a categorical cross-entropy loss function, suitable for classification tasks like this one. Compared to other common loss functions, such as the squared error cost function, catergorical cross-entropy does not suffer from the same learning slow downs as some of the others do. The optimizer is then set to use mini-batched gradient descent with a learning rate of 0.1. Lastly, the accuracy is specified as the evaluation metric used when training and testing the model.",
   "metadata": {
    "tags": [],
    "cell_id": "00017-bc2aec0d-3bb3-4a73-b322-69957ea32276",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "cell_id": "00018-a668dd8d-0061-4634-a48e-6e5a13a1a7ab",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "1939da2d",
    "execution_start": 1634205452306,
    "execution_millis": 32,
    "deepnote_cell_type": "code"
   },
   "source": "model.compile(\n    loss=keras.losses.categorical_crossentropy,\n    optimizer=keras.optimizers.SGD(lr=0.1),\n    metrics=[\"accuracy\"],\n)",
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "As we can se from the summary below, our final model contains 4 layers that ",
   "metadata": {
    "tags": [],
    "cell_id": "00019-e00cea6c-e96f-40c9-b3b2-123ce2eed840",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "source": "model.summary()",
   "metadata": {
    "tags": [],
    "cell_id": "00019-c72ec2dc-b919-4dbf-a363-2f8249969c52",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "4e6a3b95",
    "execution_start": 1634205983017,
    "execution_millis": 36,
    "deepnote_cell_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 64)                50240     \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                650       \n=================================================================\nTotal params: 55,050\nTrainable params: 55,050\nNon-trainable params: 0\n_________________________________________________________________\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": "At this point the model is ready for training. Here, two hyperparameters `batch_size` and `epochs` can be used to tweak the training process. The prior refers to the number of training samples that are passed through the network at a time, while the latter refers to the number of times the neural network is exposed to the entire dataset. \n\nTweaking these hyperparameters might both improve and worsen a model's performance. For instance, gradient descent typically doesn't reach a local or global minima after just one epoch. Hence, increasing the number of epochs might improve results up to a point were the model run the risk of overfitting, worsening it's performance on new data.",
   "metadata": {
    "tags": [],
    "cell_id": "00019-32ee47fe-ec51-4871-9df9-98faa0a9296e",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N7Aer42gk1W9",
    "cell_id": "00005-73def778-a0a3-467d-90c0-391493be5a47",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "55291826",
    "execution_start": 1634205452344,
    "execution_millis": 24071,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "fit_info = model.fit(\n    x_train,\n    y_train,\n    batch_size=batch_size,\n    epochs=epochs,\n    verbose=1,\n    validation_data=(x_test, y_test),\n)\n\nloss, accuracy = model.evaluate(x_test, y_test, verbose=0)\nprint(\"Test loss: {}, Test accuracy {}\".format(loss, accuracy))",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/10\n469/469 [==============================] - 4s 7ms/step - loss: 0.7864 - accuracy: 0.7741 - val_loss: 0.2596 - val_accuracy: 0.9237\nEpoch 2/10\n469/469 [==============================] - 2s 4ms/step - loss: 0.2494 - accuracy: 0.9274 - val_loss: 0.1964 - val_accuracy: 0.9415\nEpoch 3/10\n469/469 [==============================] - 2s 5ms/step - loss: 0.1859 - accuracy: 0.9454 - val_loss: 0.1588 - val_accuracy: 0.9527\nEpoch 4/10\n469/469 [==============================] - 2s 5ms/step - loss: 0.1555 - accuracy: 0.9542 - val_loss: 0.1467 - val_accuracy: 0.9568\nEpoch 5/10\n469/469 [==============================] - 2s 5ms/step - loss: 0.1300 - accuracy: 0.9616 - val_loss: 0.1256 - val_accuracy: 0.9620\nEpoch 6/10\n469/469 [==============================] - 2s 4ms/step - loss: 0.1132 - accuracy: 0.9673 - val_loss: 0.1185 - val_accuracy: 0.9638\nEpoch 7/10\n469/469 [==============================] - 2s 5ms/step - loss: 0.0990 - accuracy: 0.9706 - val_loss: 0.1065 - val_accuracy: 0.9672\nEpoch 8/10\n469/469 [==============================] - 2s 4ms/step - loss: 0.0867 - accuracy: 0.9734 - val_loss: 0.1017 - val_accuracy: 0.9687\nEpoch 9/10\n469/469 [==============================] - 2s 5ms/step - loss: 0.0804 - accuracy: 0.9758 - val_loss: 0.1021 - val_accuracy: 0.9691\nEpoch 10/10\n469/469 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9777 - val_loss: 0.0935 - val_accuracy: 0.9722\nTest loss: 0.09354671090841293, Test accuracy 0.9721999764442444\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "### Question 4) Auto-Encoder for denoising\n",
   "metadata": {
    "id": "0I2Bkk_rhUnH",
    "cell_id": "00006-5cd46214-2c67-4444-b7b7-21c147776254",
    "deepnote_cell_type": "markdown"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yO0HxKeJ7WFw",
    "cell_id": "00007-abd2a4bc-62f1-41a5-a53f-62f49bff3cdf",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "a095afe9",
    "execution_start": 1634205476447,
    "execution_millis": 5671,
    "deepnote_cell_type": "code"
   },
   "source": "import numpy as np\ndef salt_and_pepper(input, noise_level=0.5):\n    \"\"\"\n    This applies salt and pepper noise to the input tensor - randomly setting bits to 1 or 0.\n    Parameters\n    ----------\n    input : tensor\n        The tensor to apply salt and pepper noise to.\n    noise_level : float\n        The amount of salt and pepper noise to add.\n    Returns\n    -------\n    tensor\n        Tensor with salt and pepper noise applied.\n    \"\"\"\n    # salt and pepper noise\n    a = np.random.binomial(size=input.shape, n=1, p=(1 - noise_level))\n    b = np.random.binomial(size=input.shape, n=1, p=0.5)\n    c = (a==0) * b\n    return input * a + c\n\n\n#data preparation\nflattened_x_train = x_train.reshape(-1,784)\nflattened_x_train_seasoned = salt_and_pepper(flattened_x_train, noise_level=0.4)\n\nflattened_x_test = x_test.reshape(-1,784)\nflattened_x_test_seasoneed = salt_and_pepper(flattened_x_test, noise_level=0.4)\n",
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0GZtZH4ScQeN",
    "cell_id": "00008-2e9bc5e2-b1bf-49a7-8d60-6645be4158cd",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "3171d6b2",
    "execution_start": 1634205482170,
    "execution_millis": 86,
    "deepnote_cell_type": "code"
   },
   "source": "\nlatent_dim = 96  \n\ninput_image = keras.Input(shape=(784,))\nencoded = Dense(128, activation='relu')(input_image)\nencoded = Dense(latent_dim, activation='relu')(encoded)\ndecoded = Dense(128, activation='relu')(encoded)\ndecoded = Dense(784, activation='sigmoid')(decoded)\n\nautoencoder = keras.Model(input_image, decoded)\nencoder_only = keras.Model(input_image, encoded)\n\nencoded_input = keras.Input(shape=(latent_dim,))\ndecoder_layer = Sequential(autoencoder.layers[-2:])\ndecoder = keras.Model(encoded_input, decoder_layer(encoded_input))\n\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy')",
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "56iJOKNIKfuB",
    "cell_id": "00009-04eef254-e613-469f-946e-951be0f3bd8b",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "eac8fa9f",
    "execution_start": 1634205482274,
    "execution_millis": 250216,
    "output_cleared": false,
    "deepnote_cell_type": "code"
   },
   "source": "fit_info_AE = autoencoder.fit(\n    flattened_x_train_seasoned,\n    flattened_x_train,\n    epochs=32,\n    batch_size=64,\n    shuffle=True,\n    validation_data=(flattened_x_test_seasoneed, flattened_x_test),\n)\n",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/32\n938/938 [==============================] - 11s 11ms/step - loss: 0.2423 - val_loss: 0.1520\nEpoch 2/32\n938/938 [==============================] - 9s 10ms/step - loss: 0.1489 - val_loss: 0.1381\nEpoch 3/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1373 - val_loss: 0.1338\nEpoch 4/32\n938/938 [==============================] - 10s 10ms/step - loss: 0.1320 - val_loss: 0.1303\nEpoch 5/32\n938/938 [==============================] - 9s 9ms/step - loss: 0.1283 - val_loss: 0.1275\nEpoch 6/32\n938/938 [==============================] - 10s 10ms/step - loss: 0.1262 - val_loss: 0.1262\nEpoch 7/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1243 - val_loss: 0.1258\nEpoch 8/32\n938/938 [==============================] - 9s 10ms/step - loss: 0.1230 - val_loss: 0.1242\nEpoch 9/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1220 - val_loss: 0.1237\nEpoch 10/32\n938/938 [==============================] - 9s 10ms/step - loss: 0.1211 - val_loss: 0.1227\nEpoch 11/32\n938/938 [==============================] - 9s 10ms/step - loss: 0.1202 - val_loss: 0.1228\nEpoch 12/32\n938/938 [==============================] - 9s 9ms/step - loss: 0.1196 - val_loss: 0.1218\nEpoch 13/32\n938/938 [==============================] - 11s 11ms/step - loss: 0.1190 - val_loss: 0.1223\nEpoch 14/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1185 - val_loss: 0.1213\nEpoch 15/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1181 - val_loss: 0.1218\nEpoch 16/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1178 - val_loss: 0.1210\nEpoch 17/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1171 - val_loss: 0.1209\nEpoch 18/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1169 - val_loss: 0.1208\nEpoch 19/32\n938/938 [==============================] - 10s 10ms/step - loss: 0.1163 - val_loss: 0.1203\nEpoch 20/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1162 - val_loss: 0.1207\nEpoch 21/32\n938/938 [==============================] - 10s 10ms/step - loss: 0.1159 - val_loss: 0.1199\nEpoch 22/32\n938/938 [==============================] - 12s 12ms/step - loss: 0.1155 - val_loss: 0.1200\nEpoch 23/32\n938/938 [==============================] - 10s 10ms/step - loss: 0.1155 - val_loss: 0.1202\nEpoch 24/32\n938/938 [==============================] - 10s 11ms/step - loss: 0.1149 - val_loss: 0.1201\nEpoch 25/32\n934/938 [============================>.] - ETA: 0s - loss: 0.1151",
     "output_type": "stream"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6a021e5b830a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_x_test_seasoneed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened_x_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1139\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m   1142\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/shared-libs/python3.7/py/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2206d3be-0005-47e9-b8a0-2566096b1bac' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "colab": {
   "name": "Assignment_7_NN.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "deepnote_notebook_id": "8e3838a0-ac5b-403f-9178-04d7568e5a7d",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}